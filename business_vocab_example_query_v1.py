import requests
import time
import mysql.connector
from dotenv import load_dotenv
import os

# -------------------------- 1. åŠ è½½é…ç½®ï¼ˆæ•°æ®åº“+APIï¼‰--------------------------
load_dotenv()  # è¯»å–.envæ–‡ä»¶ä¸­çš„æ•°æ®åº“é…ç½®
DB_CONFIG = {
    'host': os.getenv('DB_HOST', 'localhost'),
    'user': os.getenv('DB_USER'),
    'password': os.getenv('DB_PASSWORD'),
    'database': 'english_study',
    'port': int(os.getenv('DB_PORT', 3306))  # æ”¯æŒè‡ªå®šä¹‰ç«¯å£ï¼ˆé»˜è®¤3306ï¼‰
}
API_DELAY = 1  # APIè¯·æ±‚é—´éš”ï¼ˆ1ç§’ï¼Œé˜²åçˆ¬ï¼‰
EMPTY_SENTENCE_MARKER = 'æš‚æ— ä¾‹å¥'  # æœªå¡«å……ä¾‹å¥çš„æ ‡è®°ï¼ˆä¸æ•°æ®åº“ä¸€è‡´ï¼‰


# -------------------------- 2. Tatoeba APIæŸ¥è¯¢ï¼ˆå¸¦å»¶è¿Ÿï¼‰--------------------------
def query_tatoeba_example(word, from_lang="eng", to_lang="cmn"):
    """è°ƒç”¨Tatoeba APIè·å–ä¸­è‹±æ–‡ä¾‹å¥ï¼Œå¸¦1ç§’å»¶è¿Ÿ"""
    # 1. é˜²åçˆ¬ï¼šè¯·æ±‚å‰å»¶è¿Ÿ1ç§’
    time.sleep(API_DELAY)
    
    # 2. æ„é€ è¯·æ±‚ï¼ˆå¤„ç†å…³é”®è¯ä¸­çš„ç©ºæ ¼ï¼Œé¿å…URLé”™è¯¯ï¼‰
    encoded_word = requests.utils.quote(word)  # å¯¹å•è¯ç¼–ç ï¼ˆå¦‚"set up"â†’"set%20up"ï¼‰
    url = f"https://tatoeba.org/en/api_v0/search?from={from_lang}&query={encoded_word}&to={to_lang}"
    
    try:
        resp = requests.get(url, timeout=10)  # è¶…æ—¶æ§åˆ¶ï¼ˆ10ç§’ï¼‰
        if resp.status_code != 200:
            print(f"âš ï¸  å•è¯[{word}] APIè¯·æ±‚å¤±è´¥ï¼ˆçŠ¶æ€ç ï¼š{resp.status_code}ï¼‰")
            return None
        
        data = resp.json()
        results = data.get("results", [])
        if not results:
            print(f"âŒ å•è¯[{word}] æœªæ‰¾åˆ°åŒ¹é…ä¾‹å¥")
            return None
        
        # 3. æå–ç¬¬ä¸€ä¸ªæœ‰æ•ˆä¾‹å¥ï¼ˆè‹±æ–‡åŸæ–‡+ä¸­æ–‡ç¿»è¯‘ï¼‰
        first_result = results[0]
        eng_sentence = first_result.get("text", "").strip()
        translations = first_result.get("translations", [])
        
        # ç¡®ä¿ä¸­æ–‡ç¿»è¯‘å­˜åœ¨ä¸”æœ‰æ•ˆ
        chn_sentence = ""
        if translations and isinstance(translations[0], list) and translations[0]:
            chn_sentence = translations[0][0].get("text", "").strip()
        
        if not eng_sentence or not chn_sentence:
            print(f"âŒ å•è¯[{word}] ä¾‹å¥æ ¼å¼ä¸å®Œæ•´ï¼ˆè‹±æ–‡ï¼š{eng_sentence}ï¼Œä¸­æ–‡ï¼š{chn_sentence}ï¼‰")
            return None
        
        print(f"âœ… å•è¯[{word}] æˆåŠŸè·å–ä¾‹å¥")
        return {
            "example_sentence": eng_sentence,
            "example_chinese": chn_sentence
        }
    
    except Exception as e:
        print(f"âš ï¸  å•è¯[{word}] APIè°ƒç”¨å¼‚å¸¸ï¼š{str(e)}")
        return None


# -------------------------- 3. æ•°æ®åº“è”åŠ¨ï¼ˆæŸ¥è¯¢å¾…è¡¥å……æ•°æ®+æ›´æ–°ï¼‰--------------------------
def update_vocab_with_examples():
    """ä»æ•°æ®åº“è¯»å–â€œæš‚æ— ä¾‹å¥â€çš„è¯æ±‡ï¼Œè°ƒç”¨APIè¡¥å……åæ›´æ–°å›æ•°æ®åº“"""
    conn = None
    cursor = None
    try:
        # 1. è¿æ¥æ•°æ®åº“
        conn = mysql.connector.connect(**DB_CONFIG)
        cursor = conn.cursor(dictionary=True)  # ç”¨å­—å…¸æ ¼å¼è¿”å›æŸ¥è¯¢ç»“æœï¼ˆä¾¿äºå–å€¼ï¼‰
        print("ğŸ“¦ æˆåŠŸè¿æ¥æ•°æ®åº“")
        
        # 2. æŸ¥è¯¢å¾…è¡¥å……ä¾‹å¥çš„æ•°æ®ï¼ˆåªæŸ¥example_sentenceä¸ºâ€œæš‚æ— ä¾‹å¥â€çš„è®°å½•ï¼‰
        query_sql = """
        SELECT id, term 
        FROM business_vocab 
        WHERE example_sentence = %s 
        ORDER BY id ASC  # æŒ‰IDé¡ºåºå¤„ç†ï¼Œé¿å…é‡å¤
        """
        cursor.execute(query_sql, (EMPTY_SENTENCE_MARKER,))
        pending_words = cursor.fetchall()  # å¾…å¤„ç†çš„è¯æ±‡åˆ—è¡¨
        
        if not pending_words:
            print("ğŸ‰ æ‰€æœ‰è¯æ±‡å·²è¡¥å……ä¾‹å¥ï¼Œæ— éœ€å¤„ç†ï¼")
            return
        
        print(f"ğŸ“‹ å…±æ‰¾åˆ° {len(pending_words)} ä¸ªå¾…è¡¥å……ä¾‹å¥çš„è¯æ±‡ï¼Œå¼€å§‹å¤„ç†...")
        
        # 3. é€ä¸ªå¤„ç†è¯æ±‡ï¼ˆæŸ¥è¯¢API+æ›´æ–°æ•°æ®åº“ï¼‰
        update_sql = """
        UPDATE business_vocab 
        SET example_sentence = %s, example_chinese = %s 
        WHERE id = %s AND example_sentence = %s  # åŠ æ¡ä»¶ï¼šç¡®ä¿åªæ›´æ–°â€œæœªå¡«å……â€çš„è®°å½•ï¼ˆé˜²è¦†ç›–ï¼‰
        """
        
        success_count = 0  # æˆåŠŸæ›´æ–°è®¡æ•°
        for vocab in pending_words:
            vocab_id = vocab["id"]
            vocab_term = vocab["term"]
            
            # è°ƒç”¨APIè·å–ä¾‹å¥
            example_data = query_tatoeba_example(vocab_term)
            if not example_data:
                continue  # è·³è¿‡è·å–å¤±è´¥çš„è¯æ±‡
            
            # æ‰§è¡Œæ•°æ®åº“æ›´æ–°ï¼ˆå¸¦é˜²è¦†ç›–æ¡ä»¶ï¼‰
            try:
                cursor.execute(
                    update_sql,
                    (
                        example_data["example_sentence"],
                        example_data["example_chinese"],
                        vocab_id,
                        EMPTY_SENTENCE_MARKER  # å…³é”®ï¼šåªæ›´æ–°â€œæš‚æ— ä¾‹å¥â€çš„è®°å½•ï¼Œé¿å…è¦†ç›–å·²æœ‰çš„
                    )
                )
                conn.commit()  # å®æ—¶æäº¤ï¼ˆé¿å…æ‰¹é‡å¤±è´¥ä¸¢å¤±æ•°æ®ï¼‰
                success_count += 1
            
            except Exception as e:
                conn.rollback()  # å•æ¡æ›´æ–°å¤±è´¥ï¼Œå›æ»šé¿å…å½±å“å…¶ä»–
                print(f"âš ï¸  è¯æ±‡[{vocab_term}]ï¼ˆIDï¼š{vocab_id}ï¼‰æ•°æ®åº“æ›´æ–°å¤±è´¥ï¼š{str(e)}")
        
        # 4. å¤„ç†å®Œæˆï¼Œè¾“å‡ºç»Ÿè®¡
        print(f"\nğŸ“Š å¤„ç†å®Œæˆï¼å…±æˆåŠŸæ›´æ–° {success_count}/{len(pending_words)} ä¸ªè¯æ±‡çš„ä¾‹å¥")
    
    except mysql.connector.Error as db_err:
        print(f"âŒ æ•°æ®åº“æ“ä½œå¼‚å¸¸ï¼š{db_err}")
    except Exception as e:
        print(f"âŒ ç¨‹åºæ•´ä½“å¼‚å¸¸ï¼š{str(e)}")
    finally:
        # 5. å…³é—­æ•°æ®åº“è¿æ¥ï¼ˆæ— è®ºæˆåŠŸ/å¤±è´¥éƒ½è¦å…³é—­ï¼‰
        if cursor:
            cursor.close()
        if conn and conn.is_connected():
            conn.close()
            print("ğŸ“¦ å·²å…³é—­æ•°æ®åº“è¿æ¥")


# -------------------------- 4. ä¸»ç¨‹åºå…¥å£ --------------------------
if __name__ == "__main__":
    print("=" * 50)
    print("ğŸ“š å•†åŠ¡è‹±è¯­è¯æ±‡ä¾‹å¥è¡¥å……å·¥å…·ï¼ˆTatoeba API + MySQLï¼‰")
    print("=" * 50)
    update_vocab_with_examples()
    print("\nğŸ‘‹ ç¨‹åºç»“æŸ")